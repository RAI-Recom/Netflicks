{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Log Data Processing\n",
    "\n",
    "This notebook processes movie log data, separating '/data/' and '/rate/' entries. It handles large files by processing data in chunks.\n",
    "\n",
    "## Imports and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "INPUT_FILE = \"../data/movie_logs.csv\"\n",
    "OUTPUT_FILE_DATA = \"../data/processed_data_entries.csv\"\n",
    "OUTPUT_FILE_RATE = \"../data/processed_rate_entries.csv\"\n",
    "CHUNKSIZE = 1000000  # Smaller chunk size for testing\n",
    "# TEST_ROWS = 10000  # Number of rows to test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Function\n",
    "\n",
    "This function processes a chunk of data, separating it into 'Data' and 'Rate' entries.\n",
    "\n",
    "- **Input**: A chunk of the CSV file (pandas DataFrame)\n",
    "- **Output**: Two DataFrames (data_entries, rate_entries)\n",
    "\n",
    "### Key Operations:\n",
    "1. Iterates through each row in the chunk\n",
    "2. Identifies 'Data' (/data/) and 'Rate' (/rate/) requests\n",
    "3. Extracts relevant information:\n",
    "   - For 'Data': timestamp, user_id, movie_title, watched_minutes\n",
    "   - For 'Rate': timestamp, user_id, movie_title, rating\n",
    "4. Cleans movie titles (replaces '+' with spaces)\n",
    "5. Handles potential errors in data processing\n",
    "\n",
    "### Note:\n",
    "- Skips incomplete data entries\n",
    "- Returns separate DataFrames for 'Data' and 'Rate' entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk):\n",
    "    \"\"\"Process a chunk of data and return transformed DataFrames for Data and Rate entries\"\"\"\n",
    "    data_entries = []\n",
    "    rate_entries = []\n",
    "    \n",
    "    for _, row in chunk.iterrows():\n",
    "        try:\n",
    "            req = row[\"request\"]\n",
    "            \n",
    "            if req.startswith(\"GET /data/\"):\n",
    "                # Process Data entry\n",
    "                parts = req.split(\"/data/\")[1].split(\"/\")\n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                \n",
    "                movie_id = parts[1].replace(\"+\", \" \")\n",
    "                minutes = parts[2].split(\".\")[0]\n",
    "                \n",
    "                data_entries.append({\n",
    "                    \"timestamp\": row[\"timestamp\"],\n",
    "                    \"user_id\": row[\"request_id\"],\n",
    "                    \"movie_title\": movie_id,\n",
    "                    \"watched_minutes\": minutes\n",
    "                })\n",
    "                \n",
    "            elif req.startswith(\"GET /rate/\"):\n",
    "                # Process Rate entry\n",
    "                rate_part = req.split(\"/rate/\")[1]\n",
    "                movie_rating = rate_part.split(\"=\")\n",
    "                if len(movie_rating) != 2:\n",
    "                    continue\n",
    "                \n",
    "                movie_id = movie_rating[0].replace(\"+\", \" \")\n",
    "                \n",
    "                rate_entries.append({\n",
    "                    \"timestamp\": row[\"timestamp\"],\n",
    "                    \"user_id\": row[\"request_id\"],\n",
    "                    \"movie_title\": movie_id,\n",
    "                    \"rating\": movie_rating[1]\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(data_entries), pd.DataFrame(rate_entries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing and File Writing\n",
    "\n",
    "- Initializes separate output files for 'Data' and 'Rate' entries with headers\n",
    "- Processes input file in chunks:\n",
    "  - Uses `process_chunk` function\n",
    "  - Appends results to respective output files\n",
    "  - Tracks progress\n",
    "- Prints total processed entries\n",
    "- Previews first 5 rows of each output file\n",
    "\n",
    "Note: Efficiently handles large datasets by processing in chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 993030 data entries and 6970 rate entries so far...\n",
      "Processed 1985946 data entries and 14054 rate entries so far...\n",
      "Processed 2978706 data entries and 21294 rate entries so far...\n",
      "Processed 3971502 data entries and 28498 rate entries so far...\n",
      "Processed 4964504 data entries and 35496 rate entries so far...\n",
      "Processed 5957825 data entries and 42175 rate entries so far...\n",
      "Processed 6951489 data entries and 48511 rate entries so far...\n",
      "Processed 7945459 data entries and 54541 rate entries so far...\n",
      "Processed 8939433 data entries and 60567 rate entries so far...\n",
      "Processed 9933687 data entries and 66313 rate entries so far...\n",
      "Processed 10927694 data entries and 72306 rate entries so far...\n",
      "Processed 11921707 data entries and 78293 rate entries so far...\n",
      "Processed 12915694 data entries and 84306 rate entries so far...\n",
      "Processed 13909537 data entries and 90463 rate entries so far...\n",
      "Processed 14903290 data entries and 96710 rate entries so far...\n",
      "Processed 15897162 data entries and 102838 rate entries so far...\n",
      "Processed 16890663 data entries and 109337 rate entries so far...\n",
      "Processed 17884392 data entries and 115608 rate entries so far...\n",
      "Processed 18877774 data entries and 122226 rate entries so far...\n",
      "Processed 19871310 data entries and 128690 rate entries so far...\n",
      "Processed 20864570 data entries and 135430 rate entries so far...\n",
      "Processed 21857882 data entries and 142118 rate entries so far...\n",
      "Processed 22851085 data entries and 148915 rate entries so far...\n",
      "Processed 23844105 data entries and 155895 rate entries so far...\n",
      "Processed 24837078 data entries and 162922 rate entries so far...\n",
      "Processed 25830014 data entries and 169986 rate entries so far...\n",
      "Processed 26822694 data entries and 177306 rate entries so far...\n",
      "Processed 27815656 data entries and 184344 rate entries so far...\n",
      "Processed 28808508 data entries and 191492 rate entries so far...\n",
      "Processed 29801620 data entries and 198380 rate entries so far...\n",
      "Processed 30795173 data entries and 204827 rate entries so far...\n",
      "Processed 31788960 data entries and 211040 rate entries so far...\n",
      "Processed 32783029 data entries and 216971 rate entries so far...\n",
      "Processed 33777161 data entries and 222839 rate entries so far...\n",
      "Processed 34771271 data entries and 228729 rate entries so far...\n",
      "Processed 35765314 data entries and 234686 rate entries so far...\n",
      "Processed 36759198 data entries and 240802 rate entries so far...\n",
      "Processed 37753111 data entries and 246889 rate entries so far...\n",
      "Processed 38746901 data entries and 253099 rate entries so far...\n",
      "Processed 39740648 data entries and 259352 rate entries so far...\n",
      "Processed 40734384 data entries and 265616 rate entries so far...\n",
      "Processed 41728068 data entries and 271932 rate entries so far...\n",
      "Processed 42721595 data entries and 278405 rate entries so far...\n",
      "Processed 43715084 data entries and 284916 rate entries so far...\n",
      "Processed 44708358 data entries and 291642 rate entries so far...\n",
      "Processed 45701764 data entries and 298236 rate entries so far...\n",
      "Processed 46694992 data entries and 305008 rate entries so far...\n",
      "Processed 47688281 data entries and 311719 rate entries so far...\n",
      "Processed 48681491 data entries and 318509 rate entries so far...\n",
      "Processed 49674570 data entries and 325430 rate entries so far...\n",
      "Processed 50667440 data entries and 332560 rate entries so far...\n",
      "Processed 51660392 data entries and 339608 rate entries so far...\n",
      "Processed 52653272 data entries and 346728 rate entries so far...\n",
      "Processed 53646111 data entries and 353889 rate entries so far...\n",
      "Processed 54639070 data entries and 360930 rate entries so far...\n",
      "Processed 55632361 data entries and 367639 rate entries so far...\n",
      "Processed 56626099 data entries and 373901 rate entries so far...\n",
      "Processed 57619969 data entries and 380031 rate entries so far...\n",
      "Processed 58614069 data entries and 385931 rate entries so far...\n",
      "Processed 59608257 data entries and 391743 rate entries so far...\n",
      "Processed 60602281 data entries and 397719 rate entries so far...\n",
      "Processed 61596346 data entries and 403654 rate entries so far...\n",
      "Processed 62590331 data entries and 409669 rate entries so far...\n",
      "Processed 63584118 data entries and 415882 rate entries so far...\n",
      "Processed 64577916 data entries and 422084 rate entries so far...\n",
      "Processed 65571655 data entries and 428345 rate entries so far...\n",
      "Processed 66565211 data entries and 434789 rate entries so far...\n",
      "Processed 67558812 data entries and 441188 rate entries so far...\n",
      "Processed 68552486 data entries and 447514 rate entries so far...\n",
      "Processed 69546007 data entries and 453993 rate entries so far...\n",
      "Processed 70539339 data entries and 460661 rate entries so far...\n",
      "Processed 70888011 data entries and 462964 rate entries so far...\n",
      "Total processed: 70888011 data entries and 462964 rate entries\n",
      "All entries saved to files\n",
      "\n",
      "Preview of Data file entries:\n",
      "             timestamp  user_id                    movie_title  \\\n",
      "0  2025-02-28T03:36:47   122156                 star wars 1977   \n",
      "1  2025-02-28T03:36:47   242890           the five senses 1999   \n",
      "2  2025-02-28T03:36:47   235684              clara and me 2004   \n",
      "3  2025-02-28T03:36:47   159468  the shawshank redemption 1994   \n",
      "4  2025-02-28T03:36:47   103729                   tangled 2010   \n",
      "\n",
      "   watched_minutes  \n",
      "0                6  \n",
      "1              100  \n",
      "2               64  \n",
      "3               64  \n",
      "4               66  \n",
      "\n",
      "Preview of Rate file entries:\n",
      "             timestamp  user_id                         movie_title  rating\n",
      "0  2025-02-28T03:36:48   265143  rare exports a christmas tale 2010       4\n",
      "1  2025-02-28T03:36:49   284982                       far away 2001       2\n",
      "2  2025-02-28T03:36:49   301905      the princess and the frog 2009       4\n",
      "3  2025-02-28T03:36:50   104416                  soul assassin 2001       3\n",
      "4  2025-02-28T03:36:51   251315                    civil brand 2003       3\n"
     ]
    }
   ],
   "source": [
    "# Initialize the output file with headers\n",
    "data_headers = [\"timestamp\", \"user_id\", \"movie_title\", \"watched_minutes\"]\n",
    "rate_headers = [\"timestamp\", \"user_id\", \"movie_title\", \"rating\"]\n",
    "\n",
    "pd.DataFrame(columns=rate_headers).to_csv(OUTPUT_FILE_RATE, index=False)\n",
    "pd.DataFrame(columns=data_headers).to_csv(OUTPUT_FILE_DATA, index=False)\n",
    "\n",
    "# Process data in chunks and write to file\n",
    "total_data_entries = 0\n",
    "total_rate_entries = 0\n",
    "\n",
    "for chunk in pd.read_csv(INPUT_FILE, header=None, \n",
    "                        names=[\"timestamp\", \"request_id\", \"request\"],\n",
    "                        chunksize=CHUNKSIZE):\n",
    "    data_df, rate_df = process_chunk(chunk)\n",
    "    \n",
    "    # Append data entries to the file\n",
    "    data_df.to_csv(OUTPUT_FILE_DATA, mode='a', header=False, index=False)\n",
    "    total_data_entries += len(data_df)\n",
    "    \n",
    "    # Append rate entries to the file\n",
    "    rate_df.to_csv(OUTPUT_FILE_RATE, mode='a', header=False, index=False)\n",
    "    total_rate_entries += len(rate_df)\n",
    "    \n",
    "    # Optional: Print progress\n",
    "    print(f\"Processed {total_data_entries} data entries and {total_rate_entries} rate entries so far...\")\n",
    "\n",
    "# Print final results\n",
    "print(f\"Total processed: {total_data_entries} data entries and {total_rate_entries} rate entries\")\n",
    "print(f\"All entries saved to files\")\n",
    "\n",
    "# Preview the results (reading just the first few lines of the output file)\n",
    "print(\"\\nPreview of Data file entries:\")\n",
    "print(pd.read_csv(OUTPUT_FILE_DATA, nrows=5))\n",
    "print(\"\\nPreview of Rate file entries:\")\n",
    "print(pd.read_csv(OUTPUT_FILE_RATE, nrows=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>watched_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>122156</td>\n",
       "      <td>star wars 1977</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>242890</td>\n",
       "      <td>the five senses 1999</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>235684</td>\n",
       "      <td>clara and me 2004</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>159468</td>\n",
       "      <td>the shawshank redemption 1994</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>103729</td>\n",
       "      <td>tangled 2010</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>149485</td>\n",
       "      <td>sos coast guard 1937</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>116756</td>\n",
       "      <td>the tunnel 2001</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>140141</td>\n",
       "      <td>in the mood for love 2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>291627</td>\n",
       "      <td>sky captain and the world of tomorrow 2004</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2025-02-28T03:36:47</td>\n",
       "      <td>240111</td>\n",
       "      <td>bells from the deep 1993</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp  user_id                                 movie_title  \\\n",
       "0   2025-02-28T03:36:47   122156                              star wars 1977   \n",
       "1   2025-02-28T03:36:47   242890                        the five senses 1999   \n",
       "2   2025-02-28T03:36:47   235684                           clara and me 2004   \n",
       "3   2025-02-28T03:36:47   159468               the shawshank redemption 1994   \n",
       "4   2025-02-28T03:36:47   103729                                tangled 2010   \n",
       "..                  ...      ...                                         ...   \n",
       "95  2025-02-28T03:36:47   149485                        sos coast guard 1937   \n",
       "96  2025-02-28T03:36:47   116756                             the tunnel 2001   \n",
       "97  2025-02-28T03:36:47   140141                   in the mood for love 2000   \n",
       "98  2025-02-28T03:36:47   291627  sky captain and the world of tomorrow 2004   \n",
       "99  2025-02-28T03:36:47   240111                    bells from the deep 1993   \n",
       "\n",
       "    watched_minutes  \n",
       "0                 6  \n",
       "1               100  \n",
       "2                64  \n",
       "3                64  \n",
       "4                66  \n",
       "..              ...  \n",
       "95              195  \n",
       "96              117  \n",
       "97                1  \n",
       "98               69  \n",
       "99               24  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "processed_file = '../data/processed_data_entries.csv'\n",
    "data_preview = pd.read_csv(processed_file, nrows=100)\n",
    "data_preview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
